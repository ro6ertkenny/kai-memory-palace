# ğŸ›‘ Validation & Hold Points
*Explicit go / no-go decisions during cluster-wide upgrades*

---

## ğŸ“Œ Purpose

This document defines **mandatory validation steps and decision checkpoints**
(â€œhold pointsâ€) during cluster-wide Kubernetes upgrades.

Upgrades fail most often not because of a bad change,
but because operators **proceed without evidence**.

Hold points exist to:
- surface regressions early
- preserve rollback options
- prevent cascading failures
- replace momentum with judgment

---

## ğŸ§  Operator Mental Model

Think of validation as **proof**, not reassurance.

- Commands completing â‰  system health
- Passing health checks â‰  workload correctness
- Silence â‰  stability

A hold point requires **evidence** before proceeding.

---

## ğŸ” Where Hold Points Occur

Hold points must exist **between every upgrade phase**:

1. After preparation
2. After control-plane upgrade
3. After each worker-node batch
4. After add-on upgrades
5. After final convergence

Skipping a hold point converts a controlled upgrade
into an uncontrolled experiment.

---

## ğŸ” What to Validate (Conceptual)

Validation should answer these questions:

### Authority & State
- Is the API responsive and stable?
- Are controllers reconciling?
- Is etcd healthy with acceptable latency?

### Execution
- Are workloads scheduling and starting?
- Are Pods running without abnormal restarts?
- Are nodes stable and reporting correctly?

### Networking & Storage
- Does DNS resolve inside the cluster?
- Do Services route traffic?
- Do volumes attach and mount correctly?

### Time & Trust
- Are certificates valid?
- Are there authentication or authorization anomalies?
- Is time synchronized across nodes?

Validation must reflect **real workload behavior**, not just system components.

---

## ğŸ›‘ Hold Point Decisions

At each hold point, operators must choose one of three actions:

### â–¶ï¸ Proceed
Evidence shows:
- stability
- convergence
- no unexplained anomalies

### â¸ Pause
Evidence is ambiguous:
- partial failures
- delayed symptoms
- unexplained noise

Pausing preserves options.

### ğŸ” Roll Back / Recover
Evidence shows:
- clear regression
- loss of stability
- trust or state violations

Rollback is a **success outcome**, not a failure.

---

## âš ï¸ Common Validation Failures (Contextual)

> **âš ï¸ Mistake: Treating kubeadm or package success as validation**  
> Tool success does not equal system health.

> **âš ï¸ Mistake: Validating only control-plane components**  
> Execution failures often surface at the workload layer.

> **âš ï¸ Mistake: Rushing because â€œthe window is openâ€**  
> Time pressure increases recovery cost.

---

## ğŸ” Delayed Failure Awareness

Some failures appear **after** the apparent success window.

Operators must:
- observe the cluster for a stability period
- watch for resource pressure
- monitor controller backlog
- review logs for recurring warnings

Delayed failures are common after:
- API changes
- add-on upgrades
- CRD migrations

---

## ğŸ§­ Reference Context

Validation and hold-point discipline documented here is grounded using the
**Raspberry Pi Kubernetes cluster** reference implementation.

Small clusters surface failures quickly because:
- margins are thin
- redundancy is limited
- convergence issues are visible

The principles documented here remain portable
across environments.

---

## ğŸ”— Related Upgrade Docs

- `README.md`  
  Defines cluster-wide upgrade ownership

- `upgrade-strategy-and-sequencing.md`  
  Defines when hold points occur

- `version-skew-and-compatibility.md`  
  Defines boundaries that validation must respect

- `addon-and-cni-upgrades.md`  
  Highlights add-on-specific validation needs

Together, these documents define **evidence-driven upgrades**.

---
